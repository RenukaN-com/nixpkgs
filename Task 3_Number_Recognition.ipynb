{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "291904b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(1212)\n",
    "\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "907a83c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec60a9b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71c26705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 2)\n"
     ]
    }
   ],
   "source": [
    "df_features = df_train.iloc[:, 1:785]\n",
    "df_label = df_train.iloc[:, 0]\n",
    "\n",
    "X_test = df_test.iloc[:, 0:784]\n",
    "\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4b554b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(df_features, df_label, \n",
    "                                                test_size=0.2,\n",
    "                                                random_state=1212)\n",
    "\n",
    "X_train = X_train.values.reshape(33600, 784)\n",
    "X_cv = X_cv.values.reshape(8400, 784)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d73bb8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 255)\n"
     ]
    }
   ],
   "source": [
    "print((min(X_train[1]), max(X_train[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0abd5212",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32'); X_cv= X_cv.astype('float32'); X_test = X_test.astype('float32')\n",
    "X_train /= 255; X_cv /= 255; X_test /= 255\n",
    "\n",
    "num_digits = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_digits)\n",
    "y_cv = keras.utils.to_categorical(y_cv, num_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e129332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0]) # 2\n",
    "print(y_train[3]) # 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa01e031",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_input = 784 \n",
    "n_hidden_1 = 300\n",
    "n_hidden_2 = 100\n",
    "n_hidden_3 = 100\n",
    "n_hidden_4 = 200\n",
    "num_digits = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1ea5492",
   "metadata": {},
   "outputs": [],
   "source": [
    "Inp = Input(shape=(784,))\n",
    "x = Dense(n_hidden_1, activation='relu', name = \"Hidden_Layer_1\")(Inp)\n",
    "x = Dense(n_hidden_2, activation='relu', name = \"Hidden_Layer_2\")(x)\n",
    "x = Dense(n_hidden_3, activation='relu', name = \"Hidden_Layer_3\")(x)\n",
    "x = Dense(n_hidden_4, activation='relu', name = \"Hidden_Layer_4\")(x)\n",
    "output = Dense(num_digits, activation='softmax', name = \"Output_Layer\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1982589a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 784)]             0         \n",
      "                                                                 \n",
      " Hidden_Layer_1 (Dense)      (None, 300)               235500    \n",
      "                                                                 \n",
      " Hidden_Layer_2 (Dense)      (None, 100)               30100     \n",
      "                                                                 \n",
      " Hidden_Layer_3 (Dense)      (None, 100)               10100     \n",
      "                                                                 \n",
      " Hidden_Layer_4 (Dense)      (None, 200)               20200     \n",
      "                                                                 \n",
      " Output_Layer (Dense)        (None, 10)                2010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 297910 (1.14 MB)\n",
      "Trainable params: 297910 (1.14 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(Inp, output)\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29b36cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "learning_rate = 0.1\n",
    "training_epochs = 20\n",
    "batch_size = 100\n",
    "\n",
    "sgd = optimizers.SGD(learning_rate=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6897fc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c745d412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "336/336 - 3s - loss: 1.8168 - accuracy: 0.4924 - val_loss: 0.9549 - val_accuracy: 0.7736 - 3s/epoch - 9ms/step\n",
      "Epoch 2/20\n",
      "336/336 - 2s - loss: 0.6088 - accuracy: 0.8401 - val_loss: 0.4413 - val_accuracy: 0.8788 - 2s/epoch - 5ms/step\n",
      "Epoch 3/20\n",
      "336/336 - 2s - loss: 0.3972 - accuracy: 0.8866 - val_loss: 0.3584 - val_accuracy: 0.8974 - 2s/epoch - 5ms/step\n",
      "Epoch 4/20\n",
      "336/336 - 2s - loss: 0.3360 - accuracy: 0.9016 - val_loss: 0.3151 - val_accuracy: 0.9089 - 2s/epoch - 5ms/step\n",
      "Epoch 5/20\n",
      "336/336 - 2s - loss: 0.2990 - accuracy: 0.9123 - val_loss: 0.2912 - val_accuracy: 0.9165 - 2s/epoch - 5ms/step\n",
      "Epoch 6/20\n",
      "336/336 - 2s - loss: 0.2721 - accuracy: 0.9204 - val_loss: 0.2682 - val_accuracy: 0.9227 - 2s/epoch - 5ms/step\n",
      "Epoch 7/20\n",
      "336/336 - 2s - loss: 0.2503 - accuracy: 0.9268 - val_loss: 0.2531 - val_accuracy: 0.9268 - 2s/epoch - 5ms/step\n",
      "Epoch 8/20\n",
      "336/336 - 2s - loss: 0.2324 - accuracy: 0.9317 - val_loss: 0.2353 - val_accuracy: 0.9320 - 2s/epoch - 5ms/step\n",
      "Epoch 9/20\n",
      "336/336 - 2s - loss: 0.2165 - accuracy: 0.9370 - val_loss: 0.2246 - val_accuracy: 0.9352 - 2s/epoch - 5ms/step\n",
      "Epoch 10/20\n",
      "336/336 - 2s - loss: 0.2025 - accuracy: 0.9411 - val_loss: 0.2168 - val_accuracy: 0.9375 - 2s/epoch - 5ms/step\n",
      "Epoch 11/20\n",
      "336/336 - 2s - loss: 0.1907 - accuracy: 0.9443 - val_loss: 0.2100 - val_accuracy: 0.9385 - 2s/epoch - 5ms/step\n",
      "Epoch 12/20\n",
      "336/336 - 2s - loss: 0.1798 - accuracy: 0.9474 - val_loss: 0.1989 - val_accuracy: 0.9431 - 2s/epoch - 5ms/step\n",
      "Epoch 13/20\n",
      "336/336 - 1s - loss: 0.1702 - accuracy: 0.9506 - val_loss: 0.1929 - val_accuracy: 0.9445 - 1s/epoch - 4ms/step\n",
      "Epoch 14/20\n",
      "336/336 - 2s - loss: 0.1603 - accuracy: 0.9528 - val_loss: 0.1815 - val_accuracy: 0.9479 - 2s/epoch - 4ms/step\n",
      "Epoch 15/20\n",
      "336/336 - 2s - loss: 0.1520 - accuracy: 0.9556 - val_loss: 0.1754 - val_accuracy: 0.9501 - 2s/epoch - 5ms/step\n",
      "Epoch 16/20\n",
      "336/336 - 2s - loss: 0.1446 - accuracy: 0.9580 - val_loss: 0.1732 - val_accuracy: 0.9490 - 2s/epoch - 5ms/step\n",
      "Epoch 17/20\n",
      "336/336 - 2s - loss: 0.1373 - accuracy: 0.9597 - val_loss: 0.1638 - val_accuracy: 0.9514 - 2s/epoch - 5ms/step\n",
      "Epoch 18/20\n",
      "336/336 - 2s - loss: 0.1309 - accuracy: 0.9617 - val_loss: 0.1622 - val_accuracy: 0.9524 - 2s/epoch - 5ms/step\n",
      "Epoch 19/20\n",
      "336/336 - 2s - loss: 0.1247 - accuracy: 0.9632 - val_loss: 0.1551 - val_accuracy: 0.9549 - 2s/epoch - 5ms/step\n",
      "Epoch 20/20\n",
      "336/336 - 2s - loss: 0.1187 - accuracy: 0.9655 - val_loss: 0.1495 - val_accuracy: 0.9568 - 2s/epoch - 5ms/step\n"
     ]
    }
   ],
   "source": [
    "history1 = model.fit(X_train, y_train,\n",
    "                     batch_size = batch_size,\n",
    "                     epochs = training_epochs,\n",
    "                     verbose = 2,\n",
    "                     validation_data=(X_cv, y_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "623bb2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "336/336 - 3s - loss: 0.3362 - accuracy: 0.8988 - val_loss: 0.1492 - val_accuracy: 0.9531 - 3s/epoch - 9ms/step\n",
      "Epoch 2/20\n",
      "336/336 - 2s - loss: 0.1213 - accuracy: 0.9624 - val_loss: 0.1044 - val_accuracy: 0.9693 - 2s/epoch - 5ms/step\n",
      "Epoch 3/20\n",
      "336/336 - 2s - loss: 0.0789 - accuracy: 0.9756 - val_loss: 0.0943 - val_accuracy: 0.9723 - 2s/epoch - 5ms/step\n",
      "Epoch 4/20\n",
      "336/336 - 2s - loss: 0.0568 - accuracy: 0.9818 - val_loss: 0.1134 - val_accuracy: 0.9656 - 2s/epoch - 5ms/step\n",
      "Epoch 5/20\n",
      "336/336 - 2s - loss: 0.0431 - accuracy: 0.9864 - val_loss: 0.1012 - val_accuracy: 0.9723 - 2s/epoch - 5ms/step\n",
      "Epoch 6/20\n",
      "336/336 - 2s - loss: 0.0352 - accuracy: 0.9886 - val_loss: 0.0946 - val_accuracy: 0.9749 - 2s/epoch - 5ms/step\n",
      "Epoch 7/20\n",
      "336/336 - 2s - loss: 0.0309 - accuracy: 0.9897 - val_loss: 0.0873 - val_accuracy: 0.9765 - 2s/epoch - 5ms/step\n",
      "Epoch 8/20\n",
      "336/336 - 2s - loss: 0.0206 - accuracy: 0.9928 - val_loss: 0.1041 - val_accuracy: 0.9756 - 2s/epoch - 5ms/step\n",
      "Epoch 9/20\n",
      "336/336 - 2s - loss: 0.0267 - accuracy: 0.9909 - val_loss: 0.1053 - val_accuracy: 0.9762 - 2s/epoch - 5ms/step\n",
      "Epoch 10/20\n",
      "336/336 - 2s - loss: 0.0202 - accuracy: 0.9939 - val_loss: 0.1285 - val_accuracy: 0.9711 - 2s/epoch - 5ms/step\n",
      "Epoch 11/20\n",
      "336/336 - 2s - loss: 0.0174 - accuracy: 0.9942 - val_loss: 0.1478 - val_accuracy: 0.9670 - 2s/epoch - 5ms/step\n",
      "Epoch 12/20\n",
      "336/336 - 2s - loss: 0.0233 - accuracy: 0.9921 - val_loss: 0.1099 - val_accuracy: 0.9745 - 2s/epoch - 5ms/step\n",
      "Epoch 13/20\n",
      "336/336 - 2s - loss: 0.0165 - accuracy: 0.9948 - val_loss: 0.1112 - val_accuracy: 0.9756 - 2s/epoch - 5ms/step\n",
      "Epoch 14/20\n",
      "336/336 - 2s - loss: 0.0168 - accuracy: 0.9945 - val_loss: 0.1080 - val_accuracy: 0.9768 - 2s/epoch - 5ms/step\n",
      "Epoch 15/20\n",
      "336/336 - 2s - loss: 0.0094 - accuracy: 0.9968 - val_loss: 0.1181 - val_accuracy: 0.9769 - 2s/epoch - 5ms/step\n",
      "Epoch 16/20\n",
      "336/336 - 2s - loss: 0.0162 - accuracy: 0.9951 - val_loss: 0.1185 - val_accuracy: 0.9740 - 2s/epoch - 5ms/step\n",
      "Epoch 17/20\n",
      "336/336 - 2s - loss: 0.0138 - accuracy: 0.9951 - val_loss: 0.1131 - val_accuracy: 0.9773 - 2s/epoch - 5ms/step\n",
      "Epoch 18/20\n",
      "336/336 - 2s - loss: 0.0145 - accuracy: 0.9957 - val_loss: 0.1182 - val_accuracy: 0.9763 - 2s/epoch - 5ms/step\n",
      "Epoch 19/20\n",
      "336/336 - 2s - loss: 0.0132 - accuracy: 0.9954 - val_loss: 0.1169 - val_accuracy: 0.9777 - 2s/epoch - 5ms/step\n",
      "Epoch 20/20\n",
      "336/336 - 2s - loss: 0.0085 - accuracy: 0.9977 - val_loss: 0.1318 - val_accuracy: 0.9755 - 2s/epoch - 5ms/step\n"
     ]
    }
   ],
   "source": [
    "Inp = Input(shape=(784,))\n",
    "x = Dense(n_hidden_1, activation='relu', name = \"Hidden_Layer_1\")(Inp)\n",
    "x = Dense(n_hidden_2, activation='relu', name = \"Hidden_Layer_2\")(x)\n",
    "x = Dense(n_hidden_3, activation='relu', name = \"Hidden_Layer_3\")(x)\n",
    "x = Dense(n_hidden_4, activation='relu', name = \"Hidden_Layer_4\")(x)\n",
    "output = Dense(num_digits, activation='softmax', name = \"Output_Layer\")(x)\n",
    "\n",
    "adam = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "model2 = Model(Inp, output)\n",
    "\n",
    "model2.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "history2 = model2.fit(X_train, y_train,\n",
    "                      batch_size = batch_size,\n",
    "                      epochs = training_epochs,\n",
    "                      verbose = 2,\n",
    "                      validation_data=(X_cv, y_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0330f637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "336/336 - 3s - loss: 0.3297 - accuracy: 0.9025 - val_loss: 0.1730 - val_accuracy: 0.9467 - 3s/epoch - 8ms/step\n",
      "Epoch 2/20\n",
      "336/336 - 2s - loss: 0.1232 - accuracy: 0.9616 - val_loss: 0.1130 - val_accuracy: 0.9636 - 2s/epoch - 5ms/step\n",
      "Epoch 3/20\n",
      "336/336 - 2s - loss: 0.0796 - accuracy: 0.9759 - val_loss: 0.1035 - val_accuracy: 0.9677 - 2s/epoch - 5ms/step\n",
      "Epoch 4/20\n",
      "336/336 - 2s - loss: 0.0578 - accuracy: 0.9820 - val_loss: 0.0951 - val_accuracy: 0.9717 - 2s/epoch - 5ms/step\n",
      "Epoch 5/20\n",
      "336/336 - 2s - loss: 0.0443 - accuracy: 0.9862 - val_loss: 0.0952 - val_accuracy: 0.9735 - 2s/epoch - 5ms/step\n",
      "Epoch 6/20\n",
      "336/336 - 2s - loss: 0.0335 - accuracy: 0.9890 - val_loss: 0.0953 - val_accuracy: 0.9739 - 2s/epoch - 5ms/step\n",
      "Epoch 7/20\n",
      "336/336 - 2s - loss: 0.0284 - accuracy: 0.9911 - val_loss: 0.1146 - val_accuracy: 0.9704 - 2s/epoch - 5ms/step\n",
      "Epoch 8/20\n",
      "336/336 - 2s - loss: 0.0239 - accuracy: 0.9920 - val_loss: 0.1165 - val_accuracy: 0.9718 - 2s/epoch - 5ms/step\n",
      "Epoch 9/20\n",
      "336/336 - 2s - loss: 0.0227 - accuracy: 0.9921 - val_loss: 0.1014 - val_accuracy: 0.9748 - 2s/epoch - 5ms/step\n",
      "Epoch 10/20\n",
      "336/336 - 2s - loss: 0.0191 - accuracy: 0.9934 - val_loss: 0.0929 - val_accuracy: 0.9782 - 2s/epoch - 5ms/step\n",
      "Epoch 11/20\n",
      "336/336 - 2s - loss: 0.0209 - accuracy: 0.9934 - val_loss: 0.1220 - val_accuracy: 0.9717 - 2s/epoch - 5ms/step\n",
      "Epoch 12/20\n",
      "336/336 - 2s - loss: 0.0207 - accuracy: 0.9931 - val_loss: 0.1076 - val_accuracy: 0.9754 - 2s/epoch - 5ms/step\n",
      "Epoch 13/20\n",
      "336/336 - 2s - loss: 0.0133 - accuracy: 0.9957 - val_loss: 0.1189 - val_accuracy: 0.9737 - 2s/epoch - 5ms/step\n",
      "Epoch 14/20\n",
      "336/336 - 2s - loss: 0.0169 - accuracy: 0.9944 - val_loss: 0.1050 - val_accuracy: 0.9768 - 2s/epoch - 5ms/step\n",
      "Epoch 15/20\n",
      "336/336 - 2s - loss: 0.0147 - accuracy: 0.9950 - val_loss: 0.1239 - val_accuracy: 0.9756 - 2s/epoch - 5ms/step\n",
      "Epoch 16/20\n",
      "336/336 - 2s - loss: 0.0181 - accuracy: 0.9946 - val_loss: 0.1191 - val_accuracy: 0.9715 - 2s/epoch - 5ms/step\n",
      "Epoch 17/20\n",
      "336/336 - 2s - loss: 0.0099 - accuracy: 0.9966 - val_loss: 0.1045 - val_accuracy: 0.9783 - 2s/epoch - 5ms/step\n",
      "Epoch 18/20\n",
      "336/336 - 2s - loss: 0.0095 - accuracy: 0.9969 - val_loss: 0.1231 - val_accuracy: 0.9763 - 2s/epoch - 5ms/step\n",
      "Epoch 19/20\n",
      "336/336 - 2s - loss: 0.0113 - accuracy: 0.9967 - val_loss: 0.1471 - val_accuracy: 0.9726 - 2s/epoch - 5ms/step\n",
      "Epoch 20/20\n",
      "336/336 - 2s - loss: 0.0093 - accuracy: 0.9977 - val_loss: 0.1166 - val_accuracy: 0.9781 - 2s/epoch - 5ms/step\n"
     ]
    }
   ],
   "source": [
    "Inp = Input(shape=(784,))\n",
    "x = Dense(n_hidden_1, activation='relu', name = \"Hidden_Layer_1\")(Inp)\n",
    "x = Dense(n_hidden_2, activation='relu', name = \"Hidden_Layer_2\")(x)\n",
    "x = Dense(n_hidden_3, activation='relu', name = \"Hidden_Layer_3\")(x)\n",
    "x = Dense(n_hidden_4, activation='relu', name = \"Hidden_Layer_4\")(x)\n",
    "output = Dense(num_digits, activation='softmax', name = \"Output_Layer\")(x)\n",
    "\n",
    "learning_rate = 0.01\n",
    "adam = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "model2a = Model(Inp, output)\n",
    "\n",
    "model2a.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "history2a = model2a.fit(X_train, y_train,\n",
    "                        batch_size = batch_size,\n",
    "                        epochs = training_epochs,\n",
    "                        verbose = 2,\n",
    "                        validation_data=(X_cv, y_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c602d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "Inp = Input(shape=(784,))\n",
    "x = Dense(n_hidden_1, activation='relu', name = \"Hidden_Layer_1\")(Inp)\n",
    "x = Dense(n_hidden_2, activation='relu', name = \"Hidden_Layer_2\")(x)\n",
    "x = Dense(n_hidden_3, activation='relu', name = \"Hidden_Layer_3\")(x)\n",
    "x = Dense(n_hidden_4, activation='relu', name = \"Hidden_Layer_4\")(x)\n",
    "output = Dense(num_digits, activation='softmax', name = \"Output_Layer\")(x)\n",
    "\n",
    "learning_rate = 0.5\n",
    "adam = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "model2b = Model(Inp, output)\n",
    "\n",
    "model2b.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "811c952e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "336/336 [==============================] - 3s 6ms/step - loss: 0.3248 - accuracy: 0.9046 - val_loss: 0.1473 - val_accuracy: 0.9552\n",
      "Epoch 2/20\n",
      "336/336 [==============================] - 2s 5ms/step - loss: 0.1192 - accuracy: 0.9634 - val_loss: 0.1291 - val_accuracy: 0.9607\n",
      "Epoch 3/20\n",
      "336/336 [==============================] - 2s 5ms/step - loss: 0.0796 - accuracy: 0.9749 - val_loss: 0.1179 - val_accuracy: 0.9660\n",
      "Epoch 4/20\n",
      "336/336 [==============================] - 2s 5ms/step - loss: 0.0567 - accuracy: 0.9820 - val_loss: 0.0987 - val_accuracy: 0.9695\n",
      "Epoch 5/20\n",
      "336/336 [==============================] - 2s 5ms/step - loss: 0.0474 - accuracy: 0.9852 - val_loss: 0.0872 - val_accuracy: 0.9746\n",
      "Epoch 6/20\n",
      "336/336 [==============================] - 2s 5ms/step - loss: 0.0327 - accuracy: 0.9894 - val_loss: 0.1237 - val_accuracy: 0.9685\n",
      "Epoch 7/20\n",
      "336/336 [==============================] - 2s 5ms/step - loss: 0.0324 - accuracy: 0.9896 - val_loss: 0.1084 - val_accuracy: 0.9711\n",
      "Epoch 8/20\n",
      "336/336 [==============================] - 2s 5ms/step - loss: 0.0283 - accuracy: 0.9908 - val_loss: 0.1080 - val_accuracy: 0.9717\n",
      "Epoch 9/20\n",
      "336/336 [==============================] - 2s 5ms/step - loss: 0.0213 - accuracy: 0.9934 - val_loss: 0.1162 - val_accuracy: 0.9714\n",
      "Epoch 10/20\n",
      "336/336 [==============================] - 2s 5ms/step - loss: 0.0203 - accuracy: 0.9928 - val_loss: 0.1293 - val_accuracy: 0.9706\n",
      "Epoch 11/20\n",
      "336/336 [==============================] - 2s 5ms/step - loss: 0.0204 - accuracy: 0.9934 - val_loss: 0.1141 - val_accuracy: 0.9750\n",
      "Epoch 12/20\n",
      "336/336 [==============================] - 2s 5ms/step - loss: 0.0192 - accuracy: 0.9937 - val_loss: 0.1002 - val_accuracy: 0.9771\n",
      "Epoch 13/20\n",
      "336/336 [==============================] - 2s 5ms/step - loss: 0.0167 - accuracy: 0.9945 - val_loss: 0.1027 - val_accuracy: 0.9751\n",
      "Epoch 14/20\n",
      "336/336 [==============================] - 2s 5ms/step - loss: 0.0191 - accuracy: 0.9936 - val_loss: 0.1147 - val_accuracy: 0.9738\n",
      "Epoch 15/20\n",
      "336/336 [==============================] - 2s 5ms/step - loss: 0.0176 - accuracy: 0.9940 - val_loss: 0.1110 - val_accuracy: 0.9755\n",
      "Epoch 16/20\n",
      "336/336 [==============================] - 2s 5ms/step - loss: 0.0091 - accuracy: 0.9973 - val_loss: 0.0992 - val_accuracy: 0.9811\n",
      "Epoch 17/20\n",
      "336/336 [==============================] - 2s 5ms/step - loss: 0.0085 - accuracy: 0.9972 - val_loss: 0.1083 - val_accuracy: 0.9768\n",
      "Epoch 18/20\n",
      "336/336 [==============================] - 2s 5ms/step - loss: 0.0148 - accuracy: 0.9954 - val_loss: 0.1021 - val_accuracy: 0.9771\n",
      "Epoch 19/20\n",
      "336/336 [==============================] - 2s 5ms/step - loss: 0.0138 - accuracy: 0.9958 - val_loss: 0.1127 - val_accuracy: 0.9758\n",
      "Epoch 20/20\n",
      "336/336 [==============================] - 2s 5ms/step - loss: 0.0129 - accuracy: 0.9961 - val_loss: 0.1178 - val_accuracy: 0.9760\n"
     ]
    }
   ],
   "source": [
    "history2b = model2b.fit(X_train, y_train,\n",
    "                        batch_size = batch_size,\n",
    "                        epochs = training_epochs,\n",
    "                            validation_data=(X_cv, y_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "187cf800",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_input = 784\n",
    "n_hidden_1 = 300\n",
    "n_hidden_2 = 100\n",
    "n_hidden_3 = 100\n",
    "n_hidden_4 = 100\n",
    "n_hidden_5 = 200\n",
    "num_digits = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "346868ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "Inp = Input(shape=(784,))\n",
    "x = Dense(n_hidden_1, activation='relu', name = \"Hidden_Layer_1\")(Inp)\n",
    "x = Dense(n_hidden_2, activation='relu', name = \"Hidden_Layer_2\")(x)\n",
    "x = Dense(n_hidden_3, activation='relu', name = \"Hidden_Layer_3\")(x)\n",
    "x = Dense(n_hidden_4, activation='relu', name = \"Hidden_Layer_4\")(x)\n",
    "x = Dense(n_hidden_5, activation='relu', name = \"Hidden_Layer_5\")(x)\n",
    "output = Dense(num_digits, activation='softmax', name = \"Output_Layer\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8df5e8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 784)]             0         \n",
      "                                                                 \n",
      " Hidden_Layer_1 (Dense)      (None, 300)               235500    \n",
      "                                                                 \n",
      " Hidden_Layer_2 (Dense)      (None, 100)               30100     \n",
      "                                                                 \n",
      " Hidden_Layer_3 (Dense)      (None, 100)               10100     \n",
      "                                                                 \n",
      " Hidden_Layer_4 (Dense)      (None, 100)               10100     \n",
      "                                                                 \n",
      " Hidden_Layer_5 (Dense)      (None, 200)               20200     \n",
      "                                                                 \n",
      " Output_Layer (Dense)        (None, 10)                2010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 308010 (1.17 MB)\n",
      "Trainable params: 308010 (1.17 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3 = Model(Inp, output)\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cbc47b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "336/336 [==============================] - 3s 6ms/step - loss: 0.3545 - accuracy: 0.8923 - val_loss: 0.1527 - val_accuracy: 0.9546\n",
      "Epoch 2/20\n",
      "336/336 [==============================] - 2s 5ms/step - loss: 0.1280 - accuracy: 0.9611 - val_loss: 0.1261 - val_accuracy: 0.9630\n",
      "Epoch 3/20\n",
      "336/336 [==============================] - 2s 5ms/step - loss: 0.0884 - accuracy: 0.9725 - val_loss: 0.1068 - val_accuracy: 0.9683\n",
      "Epoch 4/20\n",
      "336/336 [==============================] - 2s 5ms/step - loss: 0.0614 - accuracy: 0.9809 - val_loss: 0.0950 - val_accuracy: 0.9715\n",
      "Epoch 5/20\n",
      "336/336 [==============================] - 2s 5ms/step - loss: 0.0494 - accuracy: 0.9851 - val_loss: 0.1116 - val_accuracy: 0.9695\n",
      "Epoch 6/20\n",
      "336/336 [==============================] - 2s 5ms/step - loss: 0.0433 - accuracy: 0.9859 - val_loss: 0.1086 - val_accuracy: 0.9711\n",
      "Epoch 7/20\n",
      "336/336 [==============================] - 2s 5ms/step - loss: 0.0348 - accuracy: 0.9891 - val_loss: 0.1112 - val_accuracy: 0.9708\n",
      "Epoch 8/20\n",
      "336/336 [==============================] - 2s 5ms/step - loss: 0.0289 - accuracy: 0.9907 - val_loss: 0.1200 - val_accuracy: 0.9715\n",
      "Epoch 9/20\n",
      "336/336 [==============================] - 2s 5ms/step - loss: 0.0356 - accuracy: 0.9883 - val_loss: 0.1016 - val_accuracy: 0.9742\n",
      "Epoch 10/20\n",
      "336/336 [==============================] - 2s 5ms/step - loss: 0.0254 - accuracy: 0.9918 - val_loss: 0.1046 - val_accuracy: 0.9733\n",
      "Epoch 11/20\n",
      "336/336 [==============================] - 2s 5ms/step - loss: 0.0207 - accuracy: 0.9933 - val_loss: 0.1013 - val_accuracy: 0.9769\n",
      "Epoch 12/20\n",
      "336/336 [==============================] - 2s 5ms/step - loss: 0.0195 - accuracy: 0.9944 - val_loss: 0.1191 - val_accuracy: 0.9730\n",
      "Epoch 13/20\n",
      "336/336 [==============================] - 2s 5ms/step - loss: 0.0179 - accuracy: 0.9946 - val_loss: 0.1104 - val_accuracy: 0.9752\n",
      "Epoch 14/20\n",
      "336/336 [==============================] - 2s 5ms/step - loss: 0.0198 - accuracy: 0.9934 - val_loss: 0.1398 - val_accuracy: 0.9704\n",
      "Epoch 15/20\n",
      "336/336 [==============================] - 2s 5ms/step - loss: 0.0160 - accuracy: 0.9952 - val_loss: 0.1166 - val_accuracy: 0.9764\n",
      "Epoch 16/20\n",
      "336/336 [==============================] - 2s 5ms/step - loss: 0.0165 - accuracy: 0.9951 - val_loss: 0.1215 - val_accuracy: 0.9761\n",
      "Epoch 17/20\n",
      "336/336 [==============================] - 2s 5ms/step - loss: 0.0134 - accuracy: 0.9960 - val_loss: 0.1139 - val_accuracy: 0.9782\n",
      "Epoch 18/20\n",
      "336/336 [==============================] - 2s 6ms/step - loss: 0.0111 - accuracy: 0.9962 - val_loss: 0.1247 - val_accuracy: 0.9765\n",
      "Epoch 19/20\n",
      "336/336 [==============================] - 2s 6ms/step - loss: 0.0181 - accuracy: 0.9947 - val_loss: 0.1071 - val_accuracy: 0.9773\n",
      "Epoch 20/20\n",
      "336/336 [==============================] - 2s 5ms/step - loss: 0.0133 - accuracy: 0.9961 - val_loss: 0.1579 - val_accuracy: 0.9665\n"
     ]
    }
   ],
   "source": [
    "adam = keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "model3.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "history3 = model3.fit(X_train, y_train,\n",
    "                      batch_size = batch_size,\n",
    "                      epochs = training_epochs,\n",
    "                      validation_data=(X_cv, y_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dedbd78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 784)]             0         \n",
      "                                                                 \n",
      " Hidden_Layer_1 (Dense)      (None, 300)               235500    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 300)               0         \n",
      "                                                                 \n",
      " Hidden_Layer_2 (Dense)      (None, 100)               30100     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " Hidden_Layer_3 (Dense)      (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " Hidden_Layer_4 (Dense)      (None, 200)               20200     \n",
      "                                                                 \n",
      " Output_Layer (Dense)        (None, 10)                2010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 297910 (1.14 MB)\n",
      "Trainable params: 297910 (1.14 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_input = 784 # number of features\n",
    "n_hidden_1 = 300\n",
    "n_hidden_2 = 100\n",
    "n_hidden_3 = 100\n",
    "n_hidden_4 = 200\n",
    "num_digits = 10\n",
    "Inp = Input(shape=(784,))\n",
    "x = Dense(n_hidden_1, activation='relu', name = \"Hidden_Layer_1\")(Inp)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(n_hidden_2, activation='relu', name = \"Hidden_Layer_2\")(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(n_hidden_3, activation='relu', name = \"Hidden_Layer_3\")(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(n_hidden_4, activation='relu', name = \"Hidden_Layer_4\")(x)\n",
    "output = Dense(num_digits, activation='softmax', name = \"Output_Layer\")(x)\n",
    "\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f65c0a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "with h5py.File('C:\\\\Users\\\\91888\\\\Downloads\\\\xyx\\\\Lib\\\\site-packages\\\\tensorflow\\\\python\\\\keras\\\\saving\\\\__pycache__\\\\hdf5_format.cpython-311.pyc', 'w') as file:\n",
    "    dataset = file.create_dataset('data', shape=(10, 10), dtype='float32')\n",
    "    dataset[...] = 42.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f0172d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "edeeb9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5e3ba49e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data=pd.read_csv('train.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "abd20dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "66b4bd77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=pd.read_csv('train.csv')\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "298f5f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ff53f2d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a613c53950>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label=train_data.iloc[2,1:].values\n",
    "label=label.reshape(28,28)\n",
    "plt.imshow(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "36883b75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.iloc[2,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ef1d4a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=train_data.iloc[:,1:]\n",
    "Y=train_data.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f4107aeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_samples=0.5, n_estimators=200)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_samples=0.5, n_estimators=200)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_samples=0.5, n_estimators=200)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,train_size=0.7,random_state=42)\n",
    "model=RandomForestClassifier(n_estimators=200,max_samples=0.5)\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f99d7ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 1, 9, ..., 5, 0, 4], dtype=int64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=model.predict(x_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0981009e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12601,)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bc2e5bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9991496309398279"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d7dbe394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9586540750734068"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "291d071a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1186    0    4    4    2    4    9    1    2    5]\n",
      " [   0 1374    4    2    0    2    3    8    9    4]\n",
      " [   2    6 1235   16    1    2    2   17    5    5]\n",
      " [   1    1    9 1261    0   18    0    1   12   22]\n",
      " [   2    1   10    2 1180    2    4   11    6   15]\n",
      " [   0    2    1   20    0 1030    7    0    8    5]\n",
      " [   5    4    6    2    9   12 1226    0    6    2]\n",
      " [   0    0   12   16    4    1    0 1288    2   12]\n",
      " [   4    0   12   20    4    7    5    3 1145    6]\n",
      " [   0    1    1   12   23    7    0   30   14 1155]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "aba91c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      1217\n",
      "           1       0.99      0.98      0.98      1406\n",
      "           2       0.95      0.96      0.96      1291\n",
      "           3       0.93      0.95      0.94      1325\n",
      "           4       0.96      0.96      0.96      1233\n",
      "           5       0.95      0.96      0.95      1073\n",
      "           6       0.98      0.96      0.97      1272\n",
      "           7       0.95      0.96      0.96      1335\n",
      "           8       0.95      0.95      0.95      1206\n",
      "           9       0.94      0.93      0.93      1243\n",
      "\n",
      "    accuracy                           0.96     12601\n",
      "   macro avg       0.96      0.96      0.96     12601\n",
      "weighted avg       0.96      0.96      0.96     12601\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6c4be605",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'label' in test_data.columns:\n",
    "    test_data = test_data.drop(columns=['label'])  \n",
    "\n",
    "test_data_pred = model.predict(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7c932b96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 7, 6, 9], dtype=int64)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_pred=model.predict(test_data)\n",
    "test_data_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9b3f8095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a6143b3d10>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "b=test_data.iloc[24,0:].values\n",
    "b=b.reshape(28,28)\n",
    "plt.imshow(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "783f1e45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_pred[24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63852b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
